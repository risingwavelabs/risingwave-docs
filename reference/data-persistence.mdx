---
title: "Data persistence"
description: "RisingWave adopts the [Chandyâ€“Lamport algorithm](https://en.wikipedia.org/wiki/Chandy%E2%80%93Lamport%5Falgorithm) to create checkpoints. A checkpoint is a global snapshot that represents a consistent state of the entire system at a particular point in time."
mode: wide
---

When a checkpoint is created, the incremental states of streaming operators and output results are persisted in a durable and highly available remote storage. The default checkpoint interval is 1 second.

<Note>
This 1-second checkpoint interval controls RisingWave's internal fault tolerance and recovery. For sinks, data is committed to downstream systems at a different frequency controlled by `commit_checkpoint_interval`, which defaults to every 10 checkpoints (approximately 10 seconds) when sink decoupling is enabled. See [Sink decoupling](/delivery/overview#sink-decoupling) for details.
</Note>

In RisingWave, Compute Nodes perform write batching by buffering dirty states in memory before creating a checkpoint. Dirty states refer to unsaved states since the last checkpoint.

When the memory buffer exceeds a certain memory threshold (configurable), or when a checkpoint is created, the dirty states will be flushed and persisted in remote storage.

RisingWave does not require all of the data to be kept in-memory in order to function. The data can be persisted to these destinations:

* S3, or S3-compatible object storage
* Google Cloud Storage, or HDFS/WebHDFS (support implemented via [Apache OpenDAL](https://github.com/apache/incubator-opendal))

If you have more memory resources, you can generally achieve better caching and thus better performance, especially for demanding workloads. However, you can also save some costs by allocating limited memory resources to achieve moderate performance for medium or small workloads.
