---
title: Using Iceberg with RisingWave
description: "Learn how to read data from and write data to Apache Iceberg tables using RisingWave's built-in source and sink connectors."
---
RisingWave integrates with Apache Iceberg, allowing you to perform batch reads using the built-in Iceberg source connector and streaming writes using the built-in Iceberg sink connector.

This enables you to build a streaming lakehouse architecture with RisingWave. You can ingest data from Iceberg for real-time processing or sink processed results back into Iceberg, potentially using other query engines alongside RisingWave for diverse analytical needs.

## Read data from Iceberg tables (batch source)

To ingest data *from* Iceberg tables into RisingWave, use the `CREATE SOURCE` statement. For detailed syntax and parameter explanations, see [Ingest data from Iceberg](/ingestion/sources/iceberg).

The following example demonstrates creating a source that reads from an Iceberg table stored on AWS S3:

```sql
CREATE SOURCE iceberg_source
WITH (
    connector = 'iceberg',
    type='append-only',
    warehouse.path = 's3://your-bucket/path/to/iceberg/warehouse',
    database.name = 'YOUR_ICEBERG_DB',
    table.name = 'YOUR_ICEBERG_TABLE',
    s3.endpoint = 'http://YOUR_S3_ENDPOINT:PORT', -- e.g., 'http://minio:9000'
    s3.access.key = 'YOUR_ACCESS_KEY',
    s3.secret.key = 'YOUR_SECRET_KEY',
    s3.region = 'YOUR_S3_REGION'  -- Optional if endpoint is specified
) ;
```

## Write data to Iceberg tables

To stream data from RisingWave into Iceberg tables, use the CREATE SINK statement. For detailed syntax and parameter explanations,  see [Sink data to Iceberg](/integrations/destinations/apache-iceberg).

The following example assumes a stream or materialized view named `mv_name` exists in RisingWave. It demonstrates sinking data to an Iceberg table managed by a [REST catalog](https://iceberg.apache.org/concepts/catalog/#decoupling-using-the-rest-catalog).

```sql Example
CREATE SINK sink_demo_rest FROM t
WITH (
    connector = 'iceberg',
    type = 'append-only',
    force_append_only = true,
    s3.endpoint = 'https://s3.ap-southeast-2.amazonaws.com',
    s3.region = 'ap-southeast-2',
    s3.access.key = 'xxxx',
    s3.secret.key = 'xxxx',
    s3.path.style.access = 'true',
    catalog.type = 'rest',
    catalog.uri = 'http://localhost:8181/api/catalog',
    warehouse.path = 'quickstart_catalog',
    database.name = 'ns',
    table.name = 't1',
    catalog.credential='123456:123456',
    catalog.scope='PRINCIPAL_ROLE:ALL',
    catalog.oauth2_server_uri='xxx'
    catalog.scope='xxx',
);
```

<Note>Ensure that the necessary networking and credentials (like S3 access keys and catalog authentication tokens) are correctly configured and accessible from your RisingWave cluster.</Note>

## Integrate Iceberg with Amazon S3 Tables

Amazon S3 Tables introduces table management APIs compatible with the Apache Iceberg REST Catalog standard, allowing any Iceberg-compatible application to create, update, list, and delete tables in an S3 table bucket.  

This enables **Iceberg Source, Iceberg Sink, and Iceberg Table Engine** to connect with S3 Tables. Specifically, S3 Tables offer automatic compaction, so when using the Iceberg table engine with AWS S3 Tables, they provide an alternative solution until Iceberg compaction becomes available in future releases.

The following examples show how to connect, read, and write data using Iceberg with Amazon S3 Tables.

```sql
create connection my_conn
with (
    type = 'iceberg',
    warehouse.path = 'arn:aws:s3tables:us-east-1:xxxxx:bucket/xxxxx',
    s3.access.key = 'xxxx',
    s3.secret.key = 'xxxx',
    s3.region = 'us-east-1',
    catalog.uri = 'https://s3tables.us-east-1.amazonaws.com/iceberg',
    catalog.rest.signing_region='us-east-1',
    catalog.rest.sigv4_enabled=true,
    catalog.rest.signing_name='s3tables',
    catalog.type = 'rest',
);
set iceberg_engine_connection = 'public.my_conn';
alter system set iceberg_engine_connection = 'public.my_conn';

create table t(id int primary key, name varchar) with(commit_checkpoint_interval = 5) engine = iceberg;
```

```sql
create source t(*)
with (
    connector = 'iceberg',
    warehouse.path = 'arn:aws:s3tables:us-east-1:xxxxx:bucket/xxxxx',
    s3.access.key = 'xxxx',
    s3.secret.key = 'xxxx',
    s3.region = 'us-east-1',
    catalog.uri = 'https://s3tables.us-east-1.amazonaws.com/iceberg',
    catalog.rest.signing_region='us-east-1',
    catalog.rest.sigv4_enabled=true,
    catalog.rest.signing_name='s3tables',
    catalog.type = 'rest',
    table.name = 't',
    database.name = 'myns'
);
```

```sql
create table t2 (id int primary key, v int);
create sink s from t2
with (
    connector = 'iceberg',
    type = 'upsert',
    primary_key = 'id',
    warehouse.path = 'arn:aws:s3tables:us-east-1:xxxxx:bucket/xxxxx',
    s3.access.key = 'xxxx',
    s3.secret.key = 'xxxx',
    s3.region = 'us-east-1',
    catalog.uri = 'https://s3tables.us-east-1.amazonaws.com/iceberg',
    catalog.rest.signing_region='us-east-1',
    catalog.rest.sigv4_enabled=true,
    catalog.rest.signing_name='s3tables',
    catalog.type = 'rest',
    table.name = 't2',
    database.name = 'myns',
    create_table_if_not_exists = true
);
```

For details on connecting to the `rest` catalog provided by S3 Tables, refer to the [AWS documentation](https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-tables-integrating-open-source.html).