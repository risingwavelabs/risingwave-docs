---
title: "Iceberg table engine"
description: Learn how to use Iceberg table engine in RisingWave.
---

RisingWave supports using Iceberg table engine to manage Iceberg table in your catalog and Cloud storage. Follow the steps below to set up Iceberg configurations and create your table with Iceberg engine.

## 1. Create an Iceberg connection

The Iceberg connection contains information about catalog and object storage. For syntax and properties, see [`CREATE CONNECTION`](/sql/commands/sql-create-connection#syntax).

The example below creates an Iceberg connection `conn` using `storage` as catalog and `MinIO` as an S3-compatible object store.

```sql Storage catalog
CREATE CONNECTION public.conn WITH (
    type = 'iceberg',
    catalog.name = 'demo',
    catalog.type = 'storage',
    warehouse.path = 's3://hummock001/iceberg-data',
    s3.endpoint = 'http://127.0.0.1:9301',
    s3.region = 'ap-southeast-2',
    s3.access.key = 'hummockadmin',
    s3.secret.key = 'hummockadmin'
);
```

To protect your access key and secret key, you can use `SECRET` to provide your sensitive credentials.

```sql Use SECRET
CREATE SECRET secret_1 WITH (
  backend = 'meta'
) AS 'hummockadmin';
```

The following examples show how to create an Iceberg connection using different catalog types.

```sql JDBC catalog
CREATE CONNECTION public.conn WITH (
    type = 'iceberg',
    warehouse.path = 's3://hummock001/iceberg-data',
    s3.access.key = secret secret_1,
    s3.secret.key = secret secret_1,
    s3.endpoint = 'http://127.0.0.1:9301',
    s3.region = 'ap-southeast-2',
    catalog.type = 'jdbc',
    catalog.uri = 'jdbc:postgresql://127.0.0.1:8432/metadata',
    catalog.jdbc.user = 'postgres',
    catalog.jdbc.password = '123',
    catalog.name = 'dev',
);
```

```sql Glue catalog
CREATE CONNECTION public.conn WITH (
    type = 'iceberg',
    catalog.type = 'glue',
    warehouse.path = 's3://my-iceberg-bucket/test',
    s3.endpoint = 'https://s3.ap-southeast-2.amazonaws.com',
    s3.region = 'ap-southeast-2',
    s3.access.key = secret secret_1,
    s3.secret.key = secret secret_1,
);
```

```sql Rest catalog
CREATE CONNECTION public.conn WITH (
    type = 'iceberg',
    catalog.type='rest',
    catalog.uri= 'http://localhost:8181/catalog',
    warehouse.path = 'test',
    s3.endpoint = 'https://s3.ap-southeast-2.amazonaws.com',
    s3.region = 'ap-southeast-2'
    s3.access.key = secret secret_1,
    s3.secret.key = secret secret_1
);
```

## 2. Configure connection

Configure the connection for Iceberg table engine, so Iceberg table created in the next step can use the connection by default.

```sql
SET iceberg_engine_connection = 'public.conn';
ALTER system SET iceberg_engine_connection = 'public.conn';
```

## 3. Create table with Iceberg engine

Suppose creating a table with `commit_checkpoint_interval = 1`. It means RisingWave will commit changes to the iceberg table at every checkpoint. Typically, the checkpoint time is 1s. 

```sql
CREATE TABLE t (
    id INT PRIMARY KEY, 
    name VARCHAR
) WITH (commit_checkpoint_interval = 1) 
ENGINE = iceberg;

```

## 4. Insert rows

```sql
INSERT INTO t VALUES (1, 'xxx');
```

## 5. Query Iceberg table

```sql
SELECT * FROM t;
 id | name  
----+------  
  1 | xxx  
(1 row)  

```

## 6. Streaming ingestion

You can streaming ingest data to the iceberg table in a RisingWave familiar way.

<Note>
The configuration `commit_checkpoint_interval=N` for streaming ingestion. RisingWave streaming ingests data into the iceberg table and commits every N checkpoint. To mitigate the small files problem, we recommend using `commit_checkpoint_interval=60` which is the default value. Typically, if checkpoint happens every 1s, then it means we commit to iceberg table every 60s.
</Note>

You can define a connector in the table together with an iceberg engine. For example, if you use kafka connector, the table would continuously ingest data into table Iceberg table from Kafka.

```sql
CREATE TABLE t2 (
    v1 INT, 
    v2 VARCHAR
) WITH (
    connector = 'kafka',
    topic = 'kafka_1_partition_topic',
    properties.bootstrap.server = '127.0.0.1:9092',
    scan.startup.mode = 'earliest'
) 
FORMAT PLAIN ENCODE JSON 
ENGINE = iceberg;
```

You can also use `Sink into table` to ingest data into Iceberg table as well.

## 7. Cleanup

```sql
DROP TABLE t;
```

## Related topics

This section introduces additional features and considerations when using Iceberg tables in RisingWave.

### Time travel

You can run a time travel query on an Iceberg table to retrieve historical data based on a specific timestamp or snapshot ID.

```sql
-- timestamp
SELECT * FROM t FOR SYSTEM_TIME AS OF '2025-02-10 11:48:06'; 

-- snapshot id
SELECT * FROM t FOR SYSTEM_VERSION AS OF 1839661944842368408;  
```

### External Access

If an external system needs to access an Iceberg table created by RisingWave, it can reuse the Iceberg connection information from Step 1.

For example, to access the table `t` in the public schema, the corresponding namespace in the Iceberg catalog is also `public`, and the table name remains `t`.

## Limitation

Currently, there is no compaction service running for the Iceberg table, so you need to run compaction manually. We are working on this feature and plan to release it in a future version.

